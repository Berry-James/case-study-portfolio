import { ArticleHeader } from '../_components/ArticleHeader/ArticleHeader';
import { ArticleIndex } from '../_components/ArticleIndex/ArticleIndex';
import { ArticleCodeBlock } from '../_components/ArticleCodeBlock/ArticleCodeBlock';
import { ARTICLE_INDEX, articleIndexHrefEnum } from './_static/static';

export const metadata = {
  title: "Sports Science"
};

<ArticleHeader 
    title={'A priority on performance and scalability'}
    subtitle={'Building resource-demanding software for the browser'}
/>
<ArticleIndex 
    sections={ARTICLE_INDEX}
/>
<br />

## Background   
Being fortunate enough to work on such a breadth of projects in my time at Bluesky Digital Labs helped with developing a well rounded skillset as a developer.  One project in particular, is a web-based system used to upload, process and display data for high-performance athletes regarding how they run and move around the playing field.  The concept itself was intriguing, but little did I know what I was in for until our client approached the development team with his grand visions for the software.
<br />

## Technologies

I took on the role as lead frontend developer for this project, and was fortunately able to dodge the 
3rd party api integration bullet this time round.
<br />

The key functions of the NextJS frontend would be as follows:

- Plot huge .csv files in the browser (we're talking in the gigabytes) in a bar graph format    
- Automatically create teams and import athlete data via .csv files
- Display and request data for a large number of different charts, and make sure information is 
accurately displayed
<br />

###### Problem Statement

Our client's desire was to commission an entirely new system, based around the formulae and graphs in a pre-existing 
proof-of-concept system.  Our new system would need to have a strong UX focus, 
and be easily navigable by both experienced personal trainers and physios, as well as team coaches only looking for 
specific metrics.
<br />

<a id={articleIndexHrefEnum.uxUi} />
## UX/UI

The system would be complex and visually busy, there was just no getting around that.  
After carefully working with the team designer, we were able to come up with a solution that doesn't 
negatively impact performance and remains visually cohesive and clutter free.
<br />

MUI would be used as the UI library this time, as its powerful list of pre-built components 
and well documented API would help with development time on an already short deadline.
<br />

Responsiveness was also imperative, as the system would be used on both 
large desktop monitors and small laptop screens.
<br />


[INSERT SCREENSHOT OF TOP DASHBOARD HERE]
[INSERT SCREENSHOT OF TEAM PAGE HERE]
[INSERT SCREENSHOT OF PLAYER DASHBOARD HERE]

<a id={articleIndexHrefEnum.webWorkers} />
## Performance

In order to plot the data given to me in these big CSV files, I would need to ensure that the system held on to as 
little memory as possible.  Using web workers would be imperative, as keeping the render 'thread' free from intensive processing 
would ensure the system remained responsive.
<br />

CSV processing was handled with the wonderful package 'Papa Parse' [PUT LINK HERE], which has built-in web worker support, 
as well as file streaming and chunk processing.
<br />

<ArticleCodeBlock 
    code={
        `
        [PUT CODE SNIPPET OF PARSE CONFIG HERE]
        `
    }
/>
<br />

This helped immensely with performance, and would handle large files with ease (even on slower machines).
<br />

<a id={articleIndexHrefEnum.memoryManagement} />
###### Memory Management

The next hurdle would be to ensure that this whole process would work with multiple files.  Being able to select multiple files at 
once, and have them all process in sequence, would present another challenge - memory management.
<br />

Browsers don't exactly get given much memory to work with (and for good reason, they don't deserve it).  Keeping track of 
variables holding big data sets and where they're being referenced, as well as making sure they're nulled whenever they're 
finished with, would help ensure that the system could process files endlessly without running out of memory.
<br />

<ArticleCodeBlock 
    code={
        `
        [PUT CODE SNIPPET OF VARIABLE NULLING HERE]
        `
    }
/>
<br />

Another optimisation would be the use of the browser's indexed DB to store a csv's parsed data on the disk, and instead of 
parsing the file again each time it was selected, the system would read from the DB instead!  I decided to leverage the idb 
package, as it improves the developer experience significantly by turning all indexedDB interactions into promises (hooray!).

<br />
<ArticleCodeBlock 
    code={
        `
    [PUT CODE SNIPPET OF INDEXED DB CODE HERE]
        `
    }
/>
